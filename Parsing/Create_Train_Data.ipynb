{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString \n",
    "import os\n",
    "from os import listdir\n",
    "import shutil\n",
    "from pprint import pprint\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All citation styles considered in the experiment\n",
    "#american-chemical-society\n",
    "#american-medical-association\n",
    "# apa\n",
    "# chicago-annotated-bibliography\n",
    "# ieee\n",
    "# modern-language-association\n",
    "# national-library-of-medicine-grant-proposals\n",
    "# turabian-fullnote-bibliography\n",
    "# vancouver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to check if a file exists\n",
    "def deleteFile( fname ):\n",
    "    if os.path.exists(fname):\n",
    "        os.remove(fname)\n",
    "    else:\n",
    "        print(\"Can not delete the file as it doesn't exists\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#60:20:20 split for train:test:validation\n",
    "#Path to the input files , after running run_commands notebook\n",
    "def splitData(inputPath,documentType):\n",
    "    filePath = inputPath+documentType\n",
    "\n",
    "    #file name from the run_commands notebook output\n",
    "    file = \"output.no_invalid_rows.txt\"\n",
    "    folders=[]\n",
    "    \n",
    "    #Finding all styles for a particular document type\n",
    "    for r, d, f in os.walk(filePath):\n",
    "        for folder in d:\n",
    "            folders.append(os.path.join(r, folder))\n",
    "    for paths in folders:\n",
    "        fname = paths+\"/\"+file\n",
    "        \n",
    "        num_lines = 0\n",
    "        with open(fname, 'r') as f:\n",
    "            for line in f:\n",
    "                num_lines += 1\n",
    "                \n",
    "        #Calculate the number of lines for each split\n",
    "        #60:40:40 for Train:Val:Test\n",
    "        \n",
    "        train_n = int(0.6*num_lines)\n",
    "        test_n = int(0.2*num_lines)\n",
    "        #print(train_n)\n",
    "        #print(test_n)\n",
    "        \n",
    "        #Reading the input files linewise and append to a list\n",
    "        text = open(fname, 'r')\n",
    "        data = text.readlines()\n",
    "        dict = []\n",
    "        for line in data:\n",
    "            l = line.strip().split('\\n')\n",
    "            dict.append(l)\n",
    "        \n",
    "        #Validation index\n",
    "        val_n = train_n+test_n\n",
    "        print(val_n)\n",
    "        \n",
    "        #Index splicing the data for train test and validation\n",
    "        train_data= dict[0:train_n]\n",
    "        val_data=dict[train_n:val_n]\n",
    "        test_data = dict[val_n:]\n",
    "        print(\"Path is \" + paths)\n",
    "        \n",
    "        #delete if file exists\n",
    "        deleteFile(paths+\"/\"+'train.txt')\n",
    "        deleteFile(paths+\"/\"+'val.txt')    \n",
    "        deleteFile(paths+\"/\"+'test.txt')\n",
    "        \n",
    "        #Write Train data into Disk\n",
    "        file_train = open(paths+\"/\"+'train.txt','w')\n",
    "        for element in train_data:\n",
    "            file_train.write('\\n'.join(element))\n",
    "            file_train.write('\\n')\n",
    "        file_train.close()\n",
    "        \n",
    "        #val_data\n",
    "        file_val = open(paths+\"/\"+'val.txt','w')\n",
    "        for element in val_data:\n",
    "            file_val.write('\\n'.join(element))\n",
    "            file_val.write('\\n')\n",
    "        file_val.close()\n",
    "        \n",
    "        #Test Data \n",
    "        file_test = open(paths+\"/\"+'test.txt','w')\n",
    "        for element in test_data:\n",
    "            file_test.write('\\n'.join(element))\n",
    "            file_test.write('\\n')\n",
    "        file_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3590\n",
      "Path is /Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/journals/modern-language-association\n",
      "3590\n",
      "Path is /Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/journals/apa\n",
      "3590\n",
      "Path is /Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/abc/modern-language-association\n"
     ]
    }
   ],
   "source": [
    "#Path to the input files for all style data\n",
    "inputPath= \"/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/\"\n",
    "\n",
    "#Use splitData for all the document types\n",
    "splitData(inputPath,\"journals\")\n",
    "splitData(inputPath,\"proceedings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining all train,val,test files for all citation styles into one file for each document type\n",
    "\n",
    "\n",
    "def combine_files(path , documentType):\n",
    "    \n",
    "    filePaths = path+\"/\"+documentType\n",
    "    \n",
    "    train_file_name= \"train.txt\"\n",
    "    test_file_name=\"test.txt\"\n",
    "    val_file_name= \"val.txt\"\n",
    "    \n",
    "    #Path to the output filename \n",
    "    combined_train_path = path+\"/\"+documentType+\"_all_train.txt\"\n",
    "    combined_test_path= path+\"/\"+documentType+\"_all_test.txt\"\n",
    "    combined_val_path = path+\"/\"+documentType+\"_all_val.txt\"\n",
    "    \n",
    "    #delete if file exists\n",
    "    deleteFile(combined_train_path)\n",
    "    deleteFile(combined_test_path)\n",
    "    deleteFile(combined_val_path)\n",
    "    \n",
    "    folders=[]\n",
    "\n",
    "    for r, d, f in os.walk(filePaths):\n",
    "\n",
    "        for folder in d:\n",
    "            folders.append(os.path.join(r, folder))\n",
    "    for paths in folders:\n",
    "        file= open(paths+\"/\"+train_file_name)     \n",
    "        with open(combined_train_path, \"a\") as f1:\n",
    "            for line in file:\n",
    "                #print(line)\n",
    "                f1.write(line)\n",
    "    for paths in folders:\n",
    "        file= open(paths+\"/\"+ test_file_name)\n",
    "        with open(combined_test_path, \"a\") as f1:\n",
    "            for line in file:\n",
    "                #print(line)\n",
    "                f1.write(line)\n",
    "    for paths in folders:\n",
    "        file= open(paths+\"/\"+val_file_name)\n",
    "        with open(combined_val_path, \"a\") as f1:\n",
    "            for line in file:\n",
    "                #print(line)\n",
    "                f1.write(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can not delete the file as it doesn't exists\n",
      "Can not delete the file as it doesn't exists\n",
      "Can not delete the file as it doesn't exists\n",
      "Can not delete the file as it doesn't exists\n",
      "Can not delete the file as it doesn't exists\n",
      "Can not delete the file as it doesn't exists\n",
      "Can not delete the file as it doesn't exists\n",
      "Can not delete the file as it doesn't exists\n",
      "Can not delete the file as it doesn't exists\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Path to all files\n",
    "\n",
    "path = \"/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/\"\n",
    "\n",
    "#Add for different documentTypes\n",
    "combine_files(path,'journals')\n",
    "combine_files(path,'proceedings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, glob\n",
    "import shutil\n",
    "\n",
    "#Combine all train test validation from all document type into one single file\n",
    "inputPath= \"/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/\"\n",
    "trainFilename =\"all_train.txt\"\n",
    "valFilename=\"all_val.txt\"\n",
    "testFilename=\"all_test.txt\"\n",
    "filenames = glob.glob(inputPath+'*.txt')\n",
    "\n",
    "\n",
    "#TrainFile into one single train file\n",
    "with open(inputPath+trainFilename, 'wb') as outfile:\n",
    "    for filename in glob.glob(inputPath+'*_train.txt'):\n",
    "     \n",
    "        if filename == inputPath+trainFilename:\n",
    "             continue\n",
    "        with open(filename, 'rb') as readfile:\n",
    "            shutil.copyfileobj(readfile, outfile)\n",
    "\n",
    "with open(inputPath+testFilename, 'wb') as outfile:\n",
    "    for filename in glob.glob(inputPath+'*_test.txt'):\n",
    "        if filename == inputPath+testFilename:\n",
    "            continue\n",
    "        with open(filename, 'rb') as readfile:\n",
    "            shutil.copyfileobj(readfile, outfile)\n",
    "            \n",
    "with open(inputPath+valFilename, 'wb') as outfile:\n",
    "    for filename in glob.glob(inputPath+'*_val.txt'):\n",
    "        if filename == inputPath+valFilename:\n",
    "             continue\n",
    "        with open(filename, 'rb') as readfile:\n",
    "            shutil.copyfileobj(readfile, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the train/test/val for each type \n",
    "import random\n",
    "def shuffle_data(path,inputFilename,outputFilename):\n",
    "    lines = open(path+inputFilename).readlines()\n",
    "    random.shuffle(lines)\n",
    "    open(path+outputFilename, 'w').writelines(lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can not delete the file as it doesn't exists\n",
      "Can not delete the file as it doesn't exists\n",
      "Can not delete the file as it doesn't exists\n"
     ]
    }
   ],
   "source": [
    "path=\"/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/\"\n",
    "trainFile=\"all_train.txt\"\n",
    "trainshuffle=\"train.txt\"\n",
    "valFile=\"all_val.txt\"\n",
    "valShuffle=\"val.txt\"\n",
    "testFile=\"all_test.txt\"\n",
    "testShuffle=\"test.txt\"\n",
    "\n",
    "#delete shuffle file if it exists\n",
    "deleteFile(path+trainshuffle)\n",
    "deleteFile(path+testShuffle)\n",
    "deleteFile(path+valShuffle)\n",
    "\n",
    "# Shuffle train, test and valiation data \n",
    "#The final shuffled file names are train, test and val as indicated above\n",
    "\n",
    "shuffle_data(path,trainFile,trainshuffle)\n",
    "shuffle_data(path,valFile,valShuffle)\n",
    "shuffle_data(path,testFile,testShuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To divide the entire test/train/val into number of folds\n",
    "def create_folds(path,fileType):\n",
    "    fname = path+fileType+\".txt\"\n",
    "    num_lines = 0\n",
    "\n",
    "    with open(fname, 'r') as f:\n",
    "        for line in f:\n",
    "            num_lines += 1\n",
    "    print(num_lines)\n",
    "    window = int(0.1*num_lines)\n",
    "    print(window)\n",
    "    #print(each_fold)\n",
    "\n",
    "\n",
    "    text = open(fname, 'r')\n",
    "    data = text.readlines()\n",
    "    dict = []\n",
    "    for line in data:\n",
    "        l = line.strip().split('\\n')\n",
    "        dict.append(l)\n",
    "    path_to_folds = '/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/folds/'\n",
    "    start_range = 0\n",
    "    temp_range = start_range+window\n",
    "    end_range=len(dict)\n",
    "    for i in range(11):\n",
    "        #fold_i = dict[start_range:end_range]\n",
    "        deleteFile(path_to_folds+fileType+str(i)+'.txt')\n",
    "        file = open(path_to_folds+fileType+str(i)+'.txt','w')\n",
    "        \n",
    "       \n",
    "        if not (temp_range > end_range):\n",
    "            #print(file)\n",
    "            #print(str(start_range)+\":\"+ str(temp_range))\n",
    "            fold = dict[start_range:temp_range]\n",
    "            for element in fold:\n",
    "                \n",
    "                file.write('\\n'.join(element))\n",
    "                file.write('\\n')  \n",
    "            start_range = start_range + window\n",
    "            temp_range = start_range + window\n",
    "        else:\n",
    "           \n",
    "            #print(str(temp_range-window) +\":\"+str(end_range))\n",
    "            last_fold = dict[temp_range-window:end_range]\n",
    "            #print(str(temp_range-window)+\":\"+str(end_range))\n",
    "            #print(\"last\"+ str(file))\n",
    "\n",
    "            for last_elem in last_fold:\n",
    "                file.write('\\n'.join(last_elem))\n",
    "                file.write('\\n')     \n",
    "        file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfolds\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "#create folder named folds to keep the data that is divided into folds\n",
    "%cd styleData\n",
    "!pwd\n",
    "!mkdir folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2697\n",
      "269\n",
      "8079\n",
      "807\n",
      "2691\n",
      "269\n"
     ]
    }
   ],
   "source": [
    "#Path to where the input data\n",
    "path=\"/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/\"\n",
    "create_folds(path,'test')\n",
    "create_folds(path,'train')\n",
    "create_folds(path,'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/folds\n",
      "[Errno 2] No such file or directory: 'folds'\n",
      "/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/folds\n"
     ]
    }
   ],
   "source": [
    "#Creating all the folds. Make sure that you are in the correct directoty (folds where the subfolders are to be created)\n",
    "#and then mkdir accordingly. \n",
    "!pwd\n",
    "%cd folds\n",
    "!mkdir 0\n",
    "!mkdir 1\n",
    "!mkdir 2\n",
    "!mkdir 3\n",
    "!mkdir 4\n",
    "!mkdir 5\n",
    "!mkdir 6\n",
    "!mkdir 7\n",
    "!mkdir 8\n",
    "!mkdir 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/folds/9/\n"
     ]
    }
   ],
   "source": [
    "#Moving the created folds files- train,test and val into the respective fold number \n",
    "import os\n",
    "import shutil\n",
    "\n",
    "srcpath = \"/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/folds\"\n",
    "destpath = \"/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/folds/\"\n",
    "\n",
    "for root, subFolders, files in os.walk(srcpath):\n",
    "    for file in files:\n",
    "   \n",
    "        subFolder = os.path.join(destpath, file)\n",
    "      \n",
    "        #Only for the 0th fold \n",
    "        if(subFolder[-5:]) == '0.txt' and not (subFolder[-6:]) == '10.txt':\n",
    "            #print(subFolder)\n",
    "            \n",
    "            src = os.path.join(root, file)\n",
    "            dest = (root+\"/0/\")\n",
    "            if  os.path.isdir(dest):\n",
    "                shutil.move(src, dest)\n",
    "                \n",
    "        #for folds 1-9\n",
    "        for i in range(1,10):\n",
    "            if(subFolder[-5:]) == str(i)+'.txt':\n",
    "                src = os.path.join(root, file)\n",
    "                dest = (root+\"/\"+str(i)+\"/\")\n",
    "                if  os.path.isdir(dest):\n",
    "                    shutil.move(src, dest)\n",
    "                    \n",
    "        #for the extra files add to the 9th folder\n",
    "        if(subFolder[-6:]) == '10.txt':\n",
    "            src = os.path.join(root, file)\n",
    "            dest =  (root+\"/9/\")\n",
    "            if os.path.isdir(dest):\n",
    "                shutil.move(src, dest)\n",
    "         \n",
    "        \n",
    "#Combine 9th and the 10th test, train and val\n",
    "#test\n",
    "\n",
    "path = srcpath+\"/9/\"\n",
    "print(path)\n",
    "file= open(path+\"train10.txt\")\n",
    "with open(path+\"train9.txt\", \"a\") as f1:\n",
    "        for line in file:\n",
    "            #print(line)\n",
    "            f1.write(line)\n",
    "file= open(path+\"test10.txt\")\n",
    "with open(path+\"test9.txt\", \"a\") as f1:\n",
    "        for line in file:\n",
    "            #print(line)\n",
    "            f1.write(line)\n",
    "\n",
    "file= open(path+\"val10.txt\")\n",
    "with open(path+\"val9.txt\", \"a\") as f1:\n",
    "        for line in file:\n",
    "            #print(line)\n",
    "            f1.write(line)\n",
    "            \n",
    "deleteFile(path+\"train10.txt\")  \n",
    "deleteFile(path+\"test10.txt\")\n",
    "deleteFile(path+\"val10.txt\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To transform the data into label,token format\n",
    "def perform_function(inputFile, outputFile):\n",
    "\n",
    "    #write to file the output after stripping the punctuations\n",
    "    #inputFile = \"/Users/bipashabanerjee/Documents/CS/sem3/project/styleData_old/report/modern-language-association/check.txt\"\n",
    "    punctuation = string.punctuation \n",
    "    #print(punctuation)\n",
    "    text = open(inputFile, 'r')\n",
    "    data = text.readlines()\n",
    "    dict = []\n",
    "    for line in data:\n",
    "        l = line.strip().split('\\n')\n",
    "        dict.append(l)\n",
    "    #print(dict)\n",
    "    str1 = str(dict[0])\n",
    "\n",
    "    soup = BeautifulSoup(str1)\n",
    "\n",
    "\n",
    "    tag_list= []\n",
    "    for tag in soup.find_all():\n",
    "        tag_list.append(tag.name)\n",
    "\n",
    "    tag_list.remove('html')\n",
    "    tag_list.remove('body')\n",
    "    tag_list.remove('p')\n",
    "    #To find the tags associated with the particular citation style\n",
    "\n",
    "\n",
    "    for m in dict:\n",
    "        for text in m:\n",
    "\n",
    "            soup1 = BeautifulSoup(text)\n",
    "            body = soup1.find('body')\n",
    "            newtag_list= []\n",
    "            for newtag in body.find_all():\n",
    "                newtag_list.append(newtag.name)\n",
    "\n",
    "            for text_b in body:\n",
    "                file = open(outputFile,\"a+\")\n",
    "                if isinstance(text_b, NavigableString) == True:\n",
    "                    token = text_b.split()\n",
    "                    for t in token:\n",
    "                        file.write(t + \"\\t\"+ \"extra\"+'\\n')\n",
    "\n",
    "                elif text_b.name =='p':\n",
    "\n",
    "\n",
    "                    newtag_list.remove('p')\n",
    "\n",
    "                    for tag in newtag_list:\n",
    "                        text = soup.find_all(tag)\n",
    "                        for tag_text in text:\n",
    "\n",
    "                            split_text=re.split('\\s+', tag_text.text )\n",
    "                            for t in split_text:\n",
    "                                file.write(t.replace(',','') + \"\\t\"+ tag)\n",
    "\n",
    "\n",
    "                else:\n",
    "\n",
    "                    split_text=re.split('\\s+', text_b.text )   \n",
    "\n",
    "                    for t in split_text:\n",
    "\n",
    "                        if text_b.name == \"author\":\n",
    "\n",
    "                            if(t in punctuation):\n",
    "                                file.write(t+\"\\t\"+'punctuation'+'\\n')\n",
    "                            else:\n",
    "\n",
    "                                file.write(t.replace(',','')+\"\\t\"+text_b.name+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        else:\n",
    "                            if(t!='' and t ):\n",
    "                                file.write(t+\"\\t\"+ text_b.name+'\\n')\n",
    "\n",
    "            file.write(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/training\n"
     ]
    }
   ],
   "source": [
    "#make a new directory called training and test\n",
    "#in training create folds directory and all the respective folders\n",
    "!mkdir training\n",
    "!mkdir test\n",
    "%cd training\n",
    "!mkdir folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/training/folds\n"
     ]
    }
   ],
   "source": [
    "%cd folds\n",
    "!mkdir 0\n",
    "!mkdir 1\n",
    "!mkdir 2\n",
    "!mkdir 3\n",
    "!mkdir 4\n",
    "!mkdir 5\n",
    "!mkdir 6\n",
    "!mkdir 7\n",
    "!mkdir 8\n",
    "!mkdir 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To transform data into token,label format for each train,val and test for each fold\n",
    "#Change the path to test/train/val accordingly in the input and output path mentioned below\n",
    "for i in range(10):\n",
    "    inputFile = \"/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/folds/\"+str(i)+\"/val\"+str(i)+\".txt\"\n",
    "    outputFile = \"/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/training/folds/\"+str(i)+\"/val.txt\"\n",
    "\n",
    "    perform_function(inputFile,outputFile)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all tests from all folds\n",
    "\n",
    "all_test_files = \"/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/training/folds/\"\n",
    "outputPath = \"/Users/bipashabanerjee/Documents/CS/sem3/publish_new/styleData/test/\"\n",
    "\n",
    "test_file_name=\"test.txt\"\n",
    "\n",
    "folders=[]\n",
    "\n",
    "for r, d, f in os.walk(all_test_files):\n",
    "    \n",
    "    for folder in d:\n",
    "        folders.append(os.path.join(r, folder))\n",
    "for paths in folders:\n",
    "    file= open(paths+\"/\"+test_file_name)\n",
    "    with open(outputPath+\"test.txt\", \"a\") as f1:\n",
    "        for line in file:\n",
    "            #print(line)\n",
    "            f1.write(line)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove excess test data from each folds\n",
    "test_file_name=\"test.txt\"\n",
    "folders=[]\n",
    "for r, d, f in os.walk(all_test_files):\n",
    "    \n",
    "    for folder in d:\n",
    "        folders.append(os.path.join(r, folder))\n",
    "for paths in folders:\n",
    "    os.remove(paths+\"/test.txt\")\n",
    "    #file= open(paths+\"/train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zip the required files. Create a folder called data, move all the test nad the train files to the data folder. \n",
    "\n",
    "%mv training data\n",
    "%mv test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: data/ (stored 0%)\n",
      "  adding: data/test/ (stored 0%)\n",
      "  adding: data/test/test.txt (deflated 79%)\n",
      "  adding: data/training/ (stored 0%)\n",
      "  adding: data/training/.DS_Store (deflated 86%)\n",
      "  adding: data/training/folds/ (stored 0%)\n",
      "  adding: data/training/folds/.DS_Store (deflated 86%)\n",
      "  adding: data/training/folds/9/ (stored 0%)\n",
      "  adding: data/training/folds/9/train.txt (deflated 78%)\n",
      "  adding: data/training/folds/9/val.txt (deflated 79%)\n",
      "  adding: data/training/folds/0/ (stored 0%)\n",
      "  adding: data/training/folds/0/train.txt (deflated 78%)\n",
      "  adding: data/training/folds/0/val.txt (deflated 79%)\n",
      "  adding: data/training/folds/7/ (stored 0%)\n",
      "  adding: data/training/folds/7/train.txt (deflated 78%)\n",
      "  adding: data/training/folds/7/val.txt (deflated 79%)\n",
      "  adding: data/training/folds/6/ (stored 0%)\n",
      "  adding: data/training/folds/6/train.txt (deflated 79%)\n",
      "  adding: data/training/folds/6/val.txt (deflated 79%)\n",
      "  adding: data/training/folds/1/ (stored 0%)\n",
      "  adding: data/training/folds/1/train.txt (deflated 78%)\n",
      "  adding: data/training/folds/1/val.txt (deflated 79%)\n",
      "  adding: data/training/folds/8/ (stored 0%)\n",
      "  adding: data/training/folds/8/train.txt (deflated 78%)\n",
      "  adding: data/training/folds/8/val.txt (deflated 79%)\n",
      "  adding: data/training/folds/4/ (stored 0%)\n",
      "  adding: data/training/folds/4/train.txt (deflated 78%)\n",
      "  adding: data/training/folds/4/val.txt (deflated 78%)\n",
      "  adding: data/training/folds/3/ (stored 0%)\n",
      "  adding: data/training/folds/3/train.txt (deflated 78%)\n",
      "  adding: data/training/folds/3/val.txt (deflated 79%)\n",
      "  adding: data/training/folds/2/ (stored 0%)\n",
      "  adding: data/training/folds/2/train.txt (deflated 78%)\n",
      "  adding: data/training/folds/2/val.txt (deflated 79%)\n",
      "  adding: data/training/folds/5/ (stored 0%)\n",
      "  adding: data/training/folds/5/train.txt (deflated 78%)\n",
      "  adding: data/training/folds/5/val.txt (deflated 79%)\n"
     ]
    }
   ],
   "source": [
    "#Zip the data folder\n",
    "!zip -r data.zip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8079\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Utlity function to calculate number of lines\n",
    "fname = \"/Users/bipashabanerjee/Documents/CS/sem3/publish/styleData/train.txt\"\n",
    "# fname=\"/Users/bipashabanerjee/Documents/CS/sem3/project/styleData/journals/apa/train.txt\"\n",
    "num_lines=0\n",
    "with open(fname, 'r') as f:\n",
    "    for line in f:\n",
    "        num_lines += 1\n",
    "        \n",
    "print(num_lines)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
